import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
import numpy as np
from tqdm import tqdm
import os
from datetime import datetime
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

from config import Config
from data.dataset import get_data_loaders
from models.custom_cnn import CustomCNN
from models.resnet import ResNetTransfer

class BalancedFocalLoss(nn.Module):
    """ä¸“é—¨é’ˆå¯¹åŒ»å­¦å›¾åƒåˆ†ç±»çš„å¹³è¡¡Focal Loss"""
    def __init__(self, alpha=None, gamma=2.0):
        super().__init__()
        # é’ˆå¯¹ä¸¥é‡ä¸å¹³è¡¡çš„åŒ»å­¦æ•°æ®è®¾è®¡çš„æƒé‡
        if alpha is None:
            alpha = [0.2, 3.0, 6.0]  # Normal, Benign, Cancer
        
        self.alpha = torch.tensor(alpha, dtype=torch.float32)
        self.gamma = gamma
    
    def forward(self, inputs, targets):
        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = (1 - pt) ** self.gamma * ce_loss
        
        if self.alpha.device != inputs.device:
            self.alpha = self.alpha.to(inputs.device)
        
        alpha_t = self.alpha[targets]
        focal_loss = alpha_t * focal_loss
        
        return focal_loss.mean()

def train_epoch_focused(model, train_loader, criterion, optimizer, device):
    """ä¸“æ³¨è®­ç»ƒå‡½æ•° - ç›‘æ§å„ç±»åˆ«è¡¨ç°"""
    model.train()
    running_loss = 0.0
    class_correct = np.zeros(3)
    class_total = np.zeros(3)
    
    for inputs, labels in tqdm(train_loader, desc='Training', leave=False):
        inputs, labels = inputs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        
        # ç»Ÿè®¡å„ç±»åˆ«å‡†ç¡®ç‡
        for i in range(len(labels)):
            label = labels[i].item()
            class_total[label] += 1
            if predicted[i] == labels[i]:
                class_correct[label] += 1
    
    epoch_loss = running_loss / len(train_loader)
    class_accuracies = class_correct / np.maximum(class_total, 1)
    balanced_acc = np.mean(class_accuracies)
    
    return epoch_loss, balanced_acc, class_accuracies

def validate_focused(model, val_loader, criterion, device):
    """ä¸“æ³¨éªŒè¯å‡½æ•°"""
    model.eval()
    running_loss = 0.0
    all_preds = []
    all_labels = []
    class_correct = np.zeros(3)
    class_total = np.zeros(3)
    
    with torch.no_grad():
        for inputs, labels in tqdm(val_loader, desc='Validation', leave=False):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
            # ç»Ÿè®¡å„ç±»åˆ«å‡†ç¡®ç‡
            for i in range(len(labels)):
                label = labels[i].item()
                class_total[label] += 1
                if predicted[i] == labels[i]:
                    class_correct[label] += 1
    
    epoch_loss = running_loss / len(val_loader)
    class_accuracies = class_correct / np.maximum(class_total, 1)
    balanced_acc = np.mean(class_accuracies)
    
    return epoch_loss, balanced_acc, class_accuracies, np.array(all_labels), np.array(all_preds)

def train_model_final(model, train_loader, val_loader, test_loader, model_name, device):
    """æœ€ç»ˆè®­ç»ƒå‡½æ•°"""
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {model_name}...")
    
    # ä½¿ç”¨å¹³è¡¡çš„Focal Loss
    criterion = BalancedFocalLoss()
    
    # ä¼˜åŒ–å™¨è®¾ç½®
    if 'ResNet' in model_name:
        optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)
    else:
        optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-4)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5, min_lr=1e-7)
    
    best_balanced_acc = 0.0
    best_model_state = None
    patience_counter = 0
    max_patience = 6
    
    print(f"åˆå§‹å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']}")
    
    for epoch in range(15):
        print(f'\nEpoch {epoch+1}/15')
        
        # è®­ç»ƒ
        train_loss, train_bal_acc, train_class_acc = train_epoch_focused(
            model, train_loader, criterion, optimizer, device)
        
        # éªŒè¯
        val_loss, val_bal_acc, val_class_acc, _, _ = validate_focused(
            model, val_loader, criterion, device)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step(val_bal_acc)
        
        print(f'Train - Loss: {train_loss:.4f}, Bal_Acc: {train_bal_acc:.4f}')
        print(f'  Class Acc: Normal={train_class_acc[0]:.3f}, Benign={train_class_acc[1]:.3f}, Cancer={train_class_acc[2]:.3f}')
        print(f'Val   - Loss: {val_loss:.4f}, Bal_Acc: {val_bal_acc:.4f}')
        print(f'  Class Acc: Normal={val_class_acc[0]:.3f}, Benign={val_class_acc[1]:.3f}, Cancer={val_class_acc[2]:.3f}')
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_bal_acc > best_balanced_acc:
            best_balanced_acc = val_bal_acc
            best_model_state = model.state_dict().copy()
            patience_counter = 0
            print(f"ğŸ“ˆ æœ€ä½³å¹³è¡¡å‡†ç¡®ç‡: {best_balanced_acc:.4f}")
        else:
            patience_counter += 1
        
        # æ—©åœ
        if patience_counter >= max_patience:
            print("â° æ—©åœè§¦å‘")
            break
    
    # æ¢å¤æœ€ä½³æ¨¡å‹
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    # æµ‹è¯•é›†è¯„ä¼°
    print(f"\nğŸ” {model_name} æµ‹è¯•é›†è¯„ä¼°...")
    test_loss, test_bal_acc, test_class_acc, test_labels, test_preds = validate_focused(
        model, test_loader, criterion, device)
    
    print(f"æµ‹è¯•ç»“æœ:")
    print(f"  å¹³è¡¡å‡†ç¡®ç‡: {test_bal_acc:.4f} ({test_bal_acc*100:.1f}%)")
    print(f"  Normal å‡†ç¡®ç‡: {test_class_acc[0]:.3f} ({test_class_acc[0]*100:.1f}%)")
    print(f"  Benign å‡†ç¡®ç‡: {test_class_acc[1]:.3f} ({test_class_acc[1]*100:.1f}%)")
    print(f"  Cancer å‡†ç¡®ç‡: {test_class_acc[2]:.3f} ({test_class_acc[2]*100:.1f}%)")
    
    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    class_names = ['Normal', 'Benign', 'Cancer']
    print(f"\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(test_labels, test_preds, 
                              target_names=class_names, digits=3))
    
    return {
        'test_bal_acc': test_bal_acc,
        'test_class_acc': test_class_acc,
        'test_labels': test_labels,
        'test_preds': test_preds
    }

def plot_confusion_matrix_final(labels, preds, model_name, save_path):
    """ç»˜åˆ¶æœ€ç»ˆæ··æ·†çŸ©é˜µ - åªåœ¨æœ€åè°ƒç”¨"""
    plt.figure(figsize=(8, 6))
    cm = confusion_matrix(labels, preds)
    
    # ä¸­æ–‡å­—ä½“è®¾ç½®
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False
    
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Normal', 'Benign', 'Cancer'],
                yticklabels=['Normal', 'Benign', 'Cancer'])
    
    plt.title(f'{model_name} Test Confusion Matrix', fontsize=14, fontweight='bold')
    plt.ylabel('True Label', fontsize=12)
    plt.xlabel('Predicted Label', fontsize=12)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("="*70)
    print("          MTH416 æœ€ç»ˆæ­£ç¡®è®­ç»ƒ - è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜")
    print("="*70)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è·å–æ•°æ®
    train_loader, val_loader, test_loader = get_data_loaders()
    print(f"æ•°æ®é›†å¤§å°: Train={len(train_loader.dataset)}, Val={len(val_loader.dataset)}, Test={len(test_loader.dataset)}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = f'results/final_correct_{timestamp}'
    os.makedirs(save_dir, exist_ok=True)
    
    results = {}
    
    # è®­ç»ƒCNN (Q1)
    print("\n" + "="*50)
    print("          Q1: è‡ªå®šä¹‰CNNè®­ç»ƒ")
    print("="*50)
    
    cnn_model = CustomCNN().to(device)
    cnn_params = sum(p.numel() for p in cnn_model.parameters())
    print(f"CNNå‚æ•°é‡: {cnn_params:,}")
    
    cnn_results = train_model_final(cnn_model, train_loader, val_loader, test_loader, "CNN", device)
    results['cnn'] = cnn_results
    
    # è®­ç»ƒResNet (Q2)
    print("\n" + "="*50)
    print("          Q2: ResNetè¿ç§»å­¦ä¹ è®­ç»ƒ")
    print("="*50)
    
    resnet_model = ResNetTransfer().to(device)
    total_params = sum(p.numel() for p in resnet_model.parameters())
    trainable_params = sum(p.numel() for p in resnet_model.parameters() if p.requires_grad)
    print(f"ResNetæ€»å‚æ•°: {total_params:,}")
    print(f"ResNetå¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)")
    
    resnet_results = train_model_final(resnet_model, train_loader, val_loader, test_loader, "ResNet", device)
    results['resnet'] = resnet_results
    
    # ä¿å­˜æ¨¡å‹
    torch.save(cnn_model.state_dict(), os.path.join(save_dir, 'cnn_final.pth'))
    torch.save(resnet_model.state_dict(), os.path.join(save_dir, 'resnet_final.pth'))
    
    # æœ€ç»ˆç»“æœå¯¹æ¯”
    print("\n" + "="*70)
    print("                     æœ€ç»ˆç»“æœå¯¹æ¯”")
    print("="*70)
    
    print(f"Q1 (è‡ªå®šä¹‰CNN):")
    print(f"  å¹³è¡¡å‡†ç¡®ç‡: {cnn_results['test_bal_acc']:.4f} ({cnn_results['test_bal_acc']*100:.1f}%)")
    print(f"  Canceræ£€æµ‹å‡†ç¡®ç‡: {cnn_results['test_class_acc'][2]:.3f} ({cnn_results['test_class_acc'][2]*100:.1f}%)")
    
    print(f"\nQ2 (ResNetè¿ç§»å­¦ä¹ ):")
    print(f"  å¹³è¡¡å‡†ç¡®ç‡: {resnet_results['test_bal_acc']:.4f} ({resnet_results['test_bal_acc']*100:.1f}%)")
    print(f"  Canceræ£€æµ‹å‡†ç¡®ç‡: {resnet_results['test_class_acc'][2]:.3f} ({resnet_results['test_class_acc'][2]*100:.1f}%)")
    
    # æ€§èƒ½æå‡åˆ†æ
    bal_improvement = resnet_results['test_bal_acc'] - cnn_results['test_bal_acc']
    cancer_improvement = resnet_results['test_class_acc'][2] - cnn_results['test_class_acc'][2]
    
    print(f"\nğŸ“Š Q2ç›¸æ¯”Q1çš„æ”¹è¿›:")
    print(f"  å¹³è¡¡å‡†ç¡®ç‡æå‡: {bal_improvement:+.4f} ({bal_improvement*100:+.1f}ä¸ªç™¾åˆ†ç‚¹)")
    print(f"  ç™Œç—‡æ£€æµ‹æå‡: {cancer_improvement:+.3f} ({cancer_improvement*100:+.1f}ä¸ªç™¾åˆ†ç‚¹)")
    
    # å‚æ•°æ•ˆç‡åˆ†æ
    param_efficiency = trainable_params / cnn_params
    print(f"\nğŸ’¡ å‚æ•°æ•ˆç‡åˆ†æ:")
    print(f"  ResNetä»…ç”¨ {param_efficiency:.1%} çš„å¯è®­ç»ƒå‚æ•°")
    print(f"  å´è·å¾—äº†æ›´å¥½çš„æ€§èƒ½ - è¿™å°±æ˜¯è¿ç§»å­¦ä¹ çš„ä¼˜åŠ¿ï¼")
    
    # ç”Ÿæˆæœ€ç»ˆæ··æ·†çŸ©é˜µ - åªåœ¨è¿™é‡Œç”Ÿæˆï¼Œä¸åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆ
    print(f"\nğŸ“Š ç”Ÿæˆæœ€ç»ˆæ··æ·†çŸ©é˜µ...")
    plot_confusion_matrix_final(cnn_results['test_labels'], cnn_results['test_preds'], 
                               'Q1 (Custom CNN)', os.path.join(save_dir, 'q1_confusion_matrix.png'))
    plot_confusion_matrix_final(resnet_results['test_labels'], resnet_results['test_preds'], 
                               'Q2 (ResNet Transfer)', os.path.join(save_dir, 'q2_confusion_matrix.png'))
    
    # ä¿å­˜ç»“æœ
    torch.save(results, os.path.join(save_dir, 'final_results.pth'))
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆ! ç»“æœä¿å­˜åœ¨: {save_dir}")
    print(f"ğŸ“Š æ··æ·†çŸ©é˜µå·²ç”Ÿæˆ (ä»…æœ€ç»ˆç»“æœ)")
    print(f"ğŸ’¾ æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®å·²ä¿å­˜")
    
    # æˆåŠŸè¯„ä¼°
    print(f"\nğŸ¯ è®­ç»ƒè¯„ä¼°:")
    if cnn_results['test_class_acc'][2] > 0.4:  # Cancerå‡†ç¡®ç‡ > 40%
        print("âœ… CNNèƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹ç™Œç—‡")
    else:
        print("âš ï¸  CNNç™Œç—‡æ£€æµ‹èƒ½åŠ›æœ‰é™")
        
    if resnet_results['test_class_acc'][2] > cnn_results['test_class_acc'][2]:
        print("âœ… ResNetåœ¨ç™Œç—‡æ£€æµ‹ä¸Šä¼˜äºCNN")
        
    if resnet_results['test_bal_acc'] > 0.5:  # å¹³è¡¡å‡†ç¡®ç‡ > 50%
        print("âœ… ResNetè¾¾åˆ°è‰¯å¥½çš„å¹³è¡¡æ€§èƒ½")
        
    if bal_improvement > 0:
        print("âœ… è¿ç§»å­¦ä¹ å±•ç°äº†æ˜æ˜¾ä¼˜åŠ¿")

if __name__ == '__main__':
    main() 