import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
import numpy as np
from tqdm import tqdm
import os
from datetime import datetime

from config import Config
from data.dataset import get_data_loaders
from models.custom_cnn import CustomCNN
from models.resnet import ResNetTransfer
from utils.metrics import MetricsCalculator, print_metrics_summary
from utils.early_stopping import EarlyStopping

def simple_cross_entropy_loss():
    """ä½¿ç”¨ç®€å•çš„äº¤å‰ç†µæŸå¤±"""
    # è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆæ›´æ¸©å’Œï¼‰
    class_weights = torch.tensor([0.8, 1.2, 2.0], dtype=torch.float32)
    if torch.cuda.is_available():
        class_weights = class_weights.cuda()
    
    return nn.CrossEntropyLoss(weight=class_weights)

def train_epoch_simple(model, train_loader, criterion, optimizer, device):
    """ç®€åŒ–çš„è®­ç»ƒå‡½æ•°"""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    pbar = tqdm(train_loader, desc='Training')
    for inputs, labels in pbar:
        inputs, labels = inputs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        
        # æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
        
        acc = 100.0 * correct / total
        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{acc:.2f}%'})
    
    epoch_loss = running_loss / len(train_loader)
    epoch_acc = correct / total
    return epoch_loss, epoch_acc

def validate_simple(model, val_loader, criterion, device):
    """ç®€åŒ–çš„éªŒè¯å‡½æ•°"""
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        pbar = tqdm(val_loader, desc='Validation')
        for inputs, labels in pbar:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
            acc = 100.0 * correct / total
            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{acc:.2f}%'})
    
    epoch_loss = running_loss / len(val_loader)
    epoch_acc = correct / total
    
    return epoch_loss, epoch_acc, np.array(all_labels), np.array(all_preds)

def train_model_fixed(model, train_loader, val_loader, test_loader, model_name, device):
    """ä¿®å¤åçš„è®­ç»ƒå‡½æ•°"""
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {model_name}...")
    
    # ä½¿ç”¨ç®€å•çš„äº¤å‰ç†µæŸå¤±
    criterion = simple_cross_entropy_loss()
    
    # ä¿å®ˆçš„ä¼˜åŒ–å™¨è®¾ç½®
    if 'ResNet' in model_name:
        # ResNetä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡
        optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)
    else:
        # CNNä½¿ç”¨ç¨å¤§çš„å­¦ä¹ ç‡
        optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)
    
    # æ—©åœ
    early_stopping = EarlyStopping(patience=5, mode='max')
    
    best_val_acc = 0.0
    best_model_state = None
    
    print(f"åˆå§‹å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']}")
    
    for epoch in range(15):  # æœ€å¤š15è½®
        print(f'\nEpoch {epoch+1}/15')
        
        # è®­ç»ƒ
        train_loss, train_acc = train_epoch_simple(model, train_loader, criterion, optimizer, device)
        
        # éªŒè¯
        val_loss, val_acc, val_labels, val_preds = validate_simple(model, val_loader, criterion, device)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step(val_acc)
        
        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')
        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()
            print(f"ğŸ“ˆ æœ€ä½³éªŒè¯å‡†ç¡®ç‡æ›´æ–°: {best_val_acc:.4f}")
        
        # æ£€æŸ¥æ—©åœ
        early_stopping(val_acc, model)
        if early_stopping.early_stop:
            print("â° æ—©åœè§¦å‘")
            break
    
    # æ¢å¤æœ€ä½³æ¨¡å‹
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    # æµ‹è¯•é›†è¯„ä¼°
    print(f"\nğŸ” {model_name} æµ‹è¯•é›†è¯„ä¼°...")
    test_loss, test_acc, test_labels, test_preds = validate_simple(model, test_loader, criterion, device)
    
    print(f"æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc*100:.2f}%)")
    
    return {
        'train_acc': train_acc,
        'val_acc': best_val_acc,
        'test_acc': test_acc,
        'test_labels': test_labels,
        'test_preds': test_preds
    }

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("="*60)
    print("          MTH416 ä¿®å¤ç‰ˆé‡æ–°è®­ç»ƒè„šæœ¬")
    print("="*60)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # è·å–æ•°æ®
    train_loader, val_loader, test_loader = get_data_loaders()
    print(f"æ•°æ®é›†å¤§å°: Train={len(train_loader.dataset)}, Val={len(val_loader.dataset)}, Test={len(test_loader.dataset)}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = f'results/fixed_training_{timestamp}'
    os.makedirs(save_dir, exist_ok=True)
    
    results = {}
    
    # è®­ç»ƒCNN
    print("\n" + "="*40)
    print("          Q1: è‡ªå®šä¹‰CNNè®­ç»ƒ")
    print("="*40)
    
    cnn_model = CustomCNN().to(device)
    cnn_params = sum(p.numel() for p in cnn_model.parameters())
    print(f"CNNå‚æ•°é‡: {cnn_params:,}")
    
    cnn_results = train_model_fixed(cnn_model, train_loader, val_loader, test_loader, "CNN", device)
    results['cnn'] = cnn_results
    
    # ä¿å­˜CNNæ¨¡å‹
    torch.save(cnn_model.state_dict(), os.path.join(save_dir, 'cnn_model_fixed.pth'))
    
    # è®­ç»ƒResNet
    print("\n" + "="*40)
    print("          Q2: ResNetè¿ç§»å­¦ä¹ è®­ç»ƒ")
    print("="*40)
    
    resnet_model = ResNetTransfer().to(device)
    total_params = sum(p.numel() for p in resnet_model.parameters())
    trainable_params = sum(p.numel() for p in resnet_model.parameters() if p.requires_grad)
    print(f"ResNetæ€»å‚æ•°: {total_params:,}")
    print(f"ResNetå¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)")
    
    resnet_results = train_model_fixed(resnet_model, train_loader, val_loader, test_loader, "ResNet", device)
    results['resnet'] = resnet_results
    
    # ä¿å­˜ResNetæ¨¡å‹
    torch.save(resnet_model.state_dict(), os.path.join(save_dir, 'resnet_model_fixed.pth'))
    
    # ç»“æœå¯¹æ¯”
    print("\n" + "="*60)
    print("                 æœ€ç»ˆç»“æœå¯¹æ¯”")
    print("="*60)
    
    print(f"CNN  - æµ‹è¯•å‡†ç¡®ç‡: {cnn_results['test_acc']:.4f} ({cnn_results['test_acc']*100:.2f}%)")
    print(f"ResNet - æµ‹è¯•å‡†ç¡®ç‡: {resnet_results['test_acc']:.4f} ({resnet_results['test_acc']*100:.2f}%)")
    
    improvement = resnet_results['test_acc'] - cnn_results['test_acc']
    print(f"æ€§èƒ½æå‡: {improvement:+.4f} ({improvement*100:+.2f}ä¸ªç™¾åˆ†ç‚¹)")
    
    # ä¿å­˜ç»“æœ
    torch.save(results, os.path.join(save_dir, 'training_results_fixed.pth'))
    
    print(f"\nğŸ’¾ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {save_dir}")
    
    # é¢„æœŸç»“æœåˆ†æ
    print(f"\nğŸ“Š ç»“æœåˆ†æ:")
    if cnn_results['test_acc'] > 0.6:
        print("âœ… CNNæ€§èƒ½æ­£å¸¸ (>60%)")
    else:
        print("âš ï¸  CNNæ€§èƒ½ä»éœ€æ”¹è¿›")
        
    if resnet_results['test_acc'] > cnn_results['test_acc']:
        print("âœ… ResNetè¿ç§»å­¦ä¹ è¡¨ç°ä¼˜äºCNN")
    else:
        print("âš ï¸  è¿ç§»å­¦ä¹ ä¼˜åŠ¿ä¸æ˜æ˜¾")
        
    if resnet_results['test_acc'] > 0.7:
        print("âœ… ResNetè¾¾åˆ°æœŸæœ›æ€§èƒ½ (>70%)")
    else:
        print("âš ï¸  ResNetæ€§èƒ½ä»éœ€ä¼˜åŒ–")

if __name__ == '__main__':
    main() 